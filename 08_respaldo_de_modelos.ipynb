{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Respaldo de Modelos y Datos\n",
    "\n",
    "Como ya te puedes imaginar es impráctico entrenar una red cada que la vas a utilizar, sobre todo con conjuntos de datos grandes. En este notebook veremos como guardar modelos y datos. Ya sea por que vas a hacer predicciones en otro conjunto de datos o por que vas a dividir el entrenamiento en diversas etapas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import helper\n",
    "\n",
    "# fc_model es propiedad de Udacity bajo licencia MIT\n",
    "import fc_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos una transformación de los datos\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5), (0.5))])\n",
    "# Descargamos el conjunto de entrenamiento y cargamos mediante un dataLoader\n",
    "trainset = datasets.FashionMNIST('F_MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Descargamos el conjunto de validación\n",
    "testset = datasets.FashionMNIST('F_MNIST_data/', download=True, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuevamente estamos utilizando el fashion MNIST, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 389,
       "width": 389
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualizar los datos\n",
    "image, label = next(iter(trainloader))\n",
    "helper.imshow(image[0,:]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento\n",
    "\n",
    "En esta ocasión el modelo de la red está definido en el archivo *fc_model*. Esto nos permite reutilizarlo en donde queramos. A continuación cargaremos el modelo y lo entrenaremos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el modelo de red, definir el criterio a utilizar y el optimizador\n",
    "model = fc_model.Network(784, 10, [512, 256, 128])\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/2..  Training Loss: 1.670..  Test Loss: 0.975..  Test Accuracy: 0.648\n",
      "Epoch: 1/2..  Training Loss: 1.011..  Test Loss: 0.741..  Test Accuracy: 0.713\n",
      "Epoch: 1/2..  Training Loss: 0.867..  Test Loss: 0.680..  Test Accuracy: 0.737\n",
      "Epoch: 1/2..  Training Loss: 0.801..  Test Loss: 0.621..  Test Accuracy: 0.758\n",
      "Epoch: 1/2..  Training Loss: 0.759..  Test Loss: 0.600..  Test Accuracy: 0.767\n",
      "Epoch: 1/2..  Training Loss: 0.697..  Test Loss: 0.605..  Test Accuracy: 0.778\n",
      "Epoch: 1/2..  Training Loss: 0.715..  Test Loss: 0.581..  Test Accuracy: 0.781\n",
      "Epoch: 1/2..  Training Loss: 0.656..  Test Loss: 0.578..  Test Accuracy: 0.777\n",
      "Epoch: 1/2..  Training Loss: 0.712..  Test Loss: 0.555..  Test Accuracy: 0.793\n",
      "Epoch: 1/2..  Training Loss: 0.670..  Test Loss: 0.559..  Test Accuracy: 0.791\n",
      "Epoch: 1/2..  Training Loss: 0.613..  Test Loss: 0.547..  Test Accuracy: 0.801\n",
      "Epoch: 1/2..  Training Loss: 0.652..  Test Loss: 0.564..  Test Accuracy: 0.796\n",
      "Epoch: 1/2..  Training Loss: 0.640..  Test Loss: 0.559..  Test Accuracy: 0.798\n",
      "Epoch: 1/2..  Training Loss: 0.616..  Test Loss: 0.514..  Test Accuracy: 0.806\n",
      "Epoch: 1/2..  Training Loss: 0.594..  Test Loss: 0.521..  Test Accuracy: 0.803\n",
      "Epoch: 1/2..  Training Loss: 0.624..  Test Loss: 0.537..  Test Accuracy: 0.807\n",
      "Epoch: 1/2..  Training Loss: 0.572..  Test Loss: 0.519..  Test Accuracy: 0.809\n",
      "Epoch: 1/2..  Training Loss: 0.610..  Test Loss: 0.509..  Test Accuracy: 0.817\n",
      "Epoch: 1/2..  Training Loss: 0.577..  Test Loss: 0.511..  Test Accuracy: 0.811\n",
      "Epoch: 1/2..  Training Loss: 0.575..  Test Loss: 0.487..  Test Accuracy: 0.823\n",
      "Epoch: 1/2..  Training Loss: 0.582..  Test Loss: 0.513..  Test Accuracy: 0.809\n",
      "Epoch: 1/2..  Training Loss: 0.569..  Test Loss: 0.485..  Test Accuracy: 0.818\n",
      "Epoch: 1/2..  Training Loss: 0.584..  Test Loss: 0.489..  Test Accuracy: 0.817\n",
      "Epoch: 2/2..  Training Loss: 0.541..  Test Loss: 0.488..  Test Accuracy: 0.819\n",
      "Epoch: 2/2..  Training Loss: 0.547..  Test Loss: 0.472..  Test Accuracy: 0.825\n",
      "Epoch: 2/2..  Training Loss: 0.558..  Test Loss: 0.472..  Test Accuracy: 0.829\n",
      "Epoch: 2/2..  Training Loss: 0.543..  Test Loss: 0.507..  Test Accuracy: 0.819\n",
      "Epoch: 2/2..  Training Loss: 0.579..  Test Loss: 0.479..  Test Accuracy: 0.829\n",
      "Epoch: 2/2..  Training Loss: 0.547..  Test Loss: 0.484..  Test Accuracy: 0.824\n",
      "Epoch: 2/2..  Training Loss: 0.573..  Test Loss: 0.485..  Test Accuracy: 0.824\n",
      "Epoch: 2/2..  Training Loss: 0.542..  Test Loss: 0.474..  Test Accuracy: 0.830\n",
      "Epoch: 2/2..  Training Loss: 0.534..  Test Loss: 0.470..  Test Accuracy: 0.830\n",
      "Epoch: 2/2..  Training Loss: 0.529..  Test Loss: 0.482..  Test Accuracy: 0.817\n",
      "Epoch: 2/2..  Training Loss: 0.546..  Test Loss: 0.457..  Test Accuracy: 0.833\n",
      "Epoch: 2/2..  Training Loss: 0.538..  Test Loss: 0.451..  Test Accuracy: 0.837\n",
      "Epoch: 2/2..  Training Loss: 0.486..  Test Loss: 0.463..  Test Accuracy: 0.834\n",
      "Epoch: 2/2..  Training Loss: 0.520..  Test Loss: 0.461..  Test Accuracy: 0.834\n",
      "Epoch: 2/2..  Training Loss: 0.532..  Test Loss: 0.471..  Test Accuracy: 0.831\n",
      "Epoch: 2/2..  Training Loss: 0.550..  Test Loss: 0.443..  Test Accuracy: 0.839\n",
      "Epoch: 2/2..  Training Loss: 0.575..  Test Loss: 0.447..  Test Accuracy: 0.834\n",
      "Epoch: 2/2..  Training Loss: 0.508..  Test Loss: 0.469..  Test Accuracy: 0.833\n",
      "Epoch: 2/2..  Training Loss: 0.503..  Test Loss: 0.459..  Test Accuracy: 0.833\n",
      "Epoch: 2/2..  Training Loss: 0.501..  Test Loss: 0.443..  Test Accuracy: 0.840\n",
      "Epoch: 2/2..  Training Loss: 0.512..  Test Loss: 0.450..  Test Accuracy: 0.835\n",
      "Epoch: 2/2..  Training Loss: 0.519..  Test Loss: 0.435..  Test Accuracy: 0.840\n",
      "Epoch: 2/2..  Training Loss: 0.526..  Test Loss: 0.460..  Test Accuracy: 0.833\n"
     ]
    }
   ],
   "source": [
    "fc_model.train(model, trainloader, testloader, criterion, optimizer, epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Respaldo y carga\n",
    "\n",
    "Los parámetros, pesos y sesgos, de redes creadas en PyTorch se almacenan en un objeto state_dict. Veamos que contiene el objeto para la red que cargamos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo: \n",
      "\n",
      " Network(\n",
      "  (hidden_layers): ModuleList(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  )\n",
      "  (output): Linear(in_features=128, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ") \n",
      "\n",
      "State dict keys: \n",
      "\n",
      " odict_keys(['hidden_layers.0.weight', 'hidden_layers.0.bias', 'hidden_layers.1.weight', 'hidden_layers.1.bias', 'hidden_layers.2.weight', 'hidden_layers.2.bias', 'output.weight', 'output.bias'])\n"
     ]
    }
   ],
   "source": [
    "print(\"Modelo: \\n\\n\", model, '\\n')\n",
    "print(\"State dict keys: \\n\\n\", model.state_dict().keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La forma más sencilla es simplemente guardar el objeto static_dict. En este caso, podemos guardarlo a un archivo \"respaldo.pth\" usando *torch.save*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'respaldo.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y obviamente la operación contraria es cargarlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['hidden_layers.0.weight', 'hidden_layers.0.bias', 'hidden_layers.1.weight', 'hidden_layers.1.bias', 'hidden_layers.2.weight', 'hidden_layers.2.bias', 'output.weight', 'output.bias'])\n"
     ]
    }
   ],
   "source": [
    "state_dict = torch.load('respaldo.pth')\n",
    "print(state_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para insertar los parámetros en la red es necesario hacer `model.load_state_dict(state_dict)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diferente arquitectura\n",
    "\n",
    "En el ejemplo anterior parace que todo funciona bien, sin embargo, el ejemplo está limitado a casos cuando la arquitectura en la que se cargan los parámetros es exactamente igual a la arquitectura entrenada. Para casos más generales es necesario también almacenar información de la arquitectura. Esto último se realiza con un diccionario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = {'input_size': 784,\n",
    "              'output_size': 10,\n",
    "              'hidden_layers': [each.out_features for each in model.hidden_layers],\n",
    "              'state_dict': model.state_dict()}\n",
    "\n",
    "torch.save(checkpoint, 'checkpoint.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# función para cargar el modelo\n",
    "def load_checkpoint(filepath):\n",
    "    checkpoint = torch.load(filepath)\n",
    "    model = fc_model.Network(checkpoint['input_size'],\n",
    "                             checkpoint['output_size'],\n",
    "                             checkpoint['hidden_layers'])\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network(\n",
      "  (hidden_layers): ModuleList(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  )\n",
      "  (output): Linear(in_features=128, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# cargar parámetros a la red\n",
    "model = load_checkpoint('checkpoint.pth')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pptorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
